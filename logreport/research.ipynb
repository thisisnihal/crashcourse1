{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07174d91",
   "metadata": {},
   "source": [
    "### Problem \n",
    "1.You are given a raw log file which contains messages in JSON format.\n",
    "\n",
    "Example: `{“timestamp”: “2025-10-13 20:05:05”, “level”: “ERROR”, “message”: “DB failed to connect”, “service”: “UserService”}`\n",
    "\n",
    "The log file could be very large also in GBs.  \n",
    "Please create a report which contains with the following:  \n",
    "•\tCount of errors per service  :done\n",
    "•\tMost common error messages  \n",
    "•\tCount of each log levels  :done\n",
    "•\tMost 5 occurred logs with their count  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/10382253/reading-rather-large-json-files\n",
    "\n",
    "http://pypi.python.org/pypi/ijson/\n",
    "\n",
    "https://pythonspeed.com/articles/json-memory-streaming/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de536d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log per level: {'WARNING': 1676593, 'INFO': 1681122, 'CRITICAL': 1678492, 'ERROR': 1679424, 'DEBUG': 1677626}\n",
      "\n",
      "error per service: {'InventoryService': 335647, 'AuthService': 336236, 'OrderService': 335761, 'AnalyticsService': 336052, 'PaymentService': 335728}\n",
      "\n",
      "most occured errors:  [(280735, 'Cache miss occurred'), (280734, 'Cache miss occurred'), (280733, 'Cache miss occurred'), (280732, 'Cache miss occurred'), (280731, 'Cache miss occurred')]\n",
      "\n",
      "most occured logs:  [(56497, ('CRITICAL', 'InventoryService', 'User login successful')), (56496, ('CRITICAL', 'InventoryService', 'User login successful')), (56495, ('CRITICAL', 'InventoryService', 'User login successful')), (56494, ('CRITICAL', 'InventoryService', 'User login successful')), (56493, ('CRITICAL', 'InventoryService', 'User login successful'))]\n",
      "\n",
      "Execution time: 26.9762 seconds\n"
     ]
    }
   ],
   "source": [
    "# using ijson\n",
    "\n",
    "import ijson\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "log_level_freq = {}     # {Key.ERROR: 56, 'WARNING': 12}\n",
    "error_service_freq = {} # {'UserService': 12, 'AuthService': 12}\n",
    "top_logs = []           # a heap stores top k logs\n",
    "top_errors = []         # a heap stores top k error\n",
    "log_counter = {}        # {'log_message_x': 2}\n",
    "error_counter = {}      # {'error_message_1': 4}\n",
    "\n",
    "TOP_K = 5\n",
    "FILE_PATH = 'data/logs_1000mb.json'\n",
    "class Key:\n",
    "    LEVEL = 'level'\n",
    "    ERROR = 'ERROR'\n",
    "    SERVICE = 'service'\n",
    "    MESSAGE = 'message'\n",
    "\n",
    "with open(FILE_PATH, 'r') as f:\n",
    "    for log in ijson.items(f, 'item'):\n",
    "        # print(record)\n",
    "        if log[Key.LEVEL]:\n",
    "            log_level_freq[log[Key.LEVEL]] = log_level_freq.get(log[Key.LEVEL], 0) + 1\n",
    "        if log[Key.LEVEL] == Key.ERROR and log[Key.SERVICE]:\n",
    "            error_service_freq[log[Key.SERVICE]] = error_service_freq.get(log[Key.SERVICE], 0) + 1\n",
    "\n",
    "        log_key = (log.get(Key.LEVEL,''), log.get(Key.SERVICE,''), log.get(Key.MESSAGE,''))\n",
    "        log_count = log_counter.get(log_key, 0) + 1\n",
    "\n",
    "        log_counter[log_key] = log_count\n",
    "        heapq.heappush(top_logs, (log_count, log_key))\n",
    "        if len(top_logs) > TOP_K:\n",
    "            heapq.heappop(top_logs)\n",
    "\n",
    "        if log.get(Key.LEVEL) == Key.ERROR:\n",
    "            msg = log.get(Key.MESSAGE,'')\n",
    "            err_count = error_counter.get(msg, 0) + 1\n",
    "            error_counter[msg] = err_count\n",
    "            heapq.heappush(top_errors, (err_count, msg))\n",
    "            if len(top_errors) > TOP_K:\n",
    "                heapq.heappop(top_errors)\n",
    "\n",
    "\n",
    "print('log per level:', log_level_freq)\n",
    "print('\\nerror per service:', error_service_freq)\n",
    "\n",
    "most_occured_logs = sorted(top_logs, reverse=True)\n",
    "most_occured_errors = sorted(top_errors, reverse=True)\n",
    "\n",
    "print(\"\\nmost occured errors: \", most_occured_errors)\n",
    "print(\"\\nmost occured logs: \", most_occured_logs)\n",
    "\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class KthLargest:\n",
    "    def __init__(self, k: int, data):\n",
    "        \"\"\"\"\"\"\n",
    "        self.minHeap = []\n",
    "        self.k = k\n",
    "        for e in data:\n",
    "            heapq.heappush(self.minHeap, e)\n",
    "            if len(self.minHeap) > k:\n",
    "                heapq.heappop(self.minHeap)\n",
    "\n",
    "    def add(self, val: int) -> int:\n",
    "        heapq.heappush(self.minHeap, val)\n",
    "        if len(self.minHeap) > self.k:\n",
    "            heapq.heappop(self.minHeap)\n",
    "        return self.minHeap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054a7823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log per level: {'WARNING': 1676593, 'INFO': 1681122, 'CRITICAL': 1678492, 'ERROR': 1679424, 'DEBUG': 1677626}\n",
      "\n",
      "error per service: {'InventoryService': 335647, 'AuthService': 336236, 'OrderService': 335761, 'AnalyticsService': 336052, 'PaymentService': 335728}\n",
      "\n",
      "most occured errors:  [(280735, 'Cache miss occurred'), (280734, 'Cache miss occurred'), (280733, 'Cache miss occurred'), (280732, 'Cache miss occurred'), (280731, 'Cache miss occurred')]\n",
      "\n",
      "most occured logs:  [(56497, ('CRITICAL', 'InventoryService', 'User login successful')), (56496, ('CRITICAL', 'InventoryService', 'User login successful')), (56495, ('CRITICAL', 'InventoryService', 'User login successful')), (56494, ('CRITICAL', 'InventoryService', 'User login successful')), (56493, ('CRITICAL', 'InventoryService', 'User login successful'))]\n",
      "\n",
      "Execution time: 26.9048 seconds\n"
     ]
    }
   ],
   "source": [
    "# using json\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "log_level_freq = {}     # {Key.ERROR: 56, 'WARNING': 12}\n",
    "error_service_freq = {} # {'UserService': 12, 'AuthService': 12}\n",
    "top_logs = []           # a heap stores top k logs\n",
    "top_errors = []         # a heap stores top k error\n",
    "log_counter = {}        # {'log_message_x': 2}\n",
    "error_counter = {}      # {'error_message_1': 4}\n",
    "FILE_PATH = 'data/logs_1000mb.json'\n",
    "TOP_K = 5\n",
    "class Key:\n",
    "    LEVEL = 'level'\n",
    "    ERROR = 'ERROR'\n",
    "    SERVICE = 'service'\n",
    "    MESSAGE = 'message'\n",
    "\n",
    "f = open(FILE_PATH)\n",
    "import json\n",
    "logs = json.load(f)\n",
    "for index, log in enumerate(logs):\n",
    "        if log[Key.LEVEL]:\n",
    "            log_level_freq[log[Key.LEVEL]] = log_level_freq.get(log[Key.LEVEL], 0) + 1\n",
    "        if log[Key.LEVEL] == Key.ERROR and log[Key.SERVICE]:\n",
    "            error_service_freq[log[Key.SERVICE]] = error_service_freq.get(log[Key.SERVICE], 0) + 1\n",
    "\n",
    "        log_key = (log.get(Key.LEVEL,''), log.get(Key.SERVICE,''), log.get(Key.MESSAGE,''))\n",
    "        log_count = log_counter.get(log_key, 0) + 1\n",
    "\n",
    "        log_counter[log_key] = log_count\n",
    "        heapq.heappush(top_logs, (log_count, log_key))\n",
    "        if len(top_logs) > TOP_K:\n",
    "            heapq.heappop(top_logs)\n",
    "\n",
    "        if log.get(Key.LEVEL) == Key.ERROR:\n",
    "            msg = log.get(Key.MESSAGE,'')\n",
    "            err_count = error_counter.get(msg, 0) + 1\n",
    "            error_counter[msg] = err_count\n",
    "            heapq.heappush(top_errors, (err_count, msg))\n",
    "            if len(top_errors) > TOP_K:\n",
    "                heapq.heappop(top_errors)\n",
    "\n",
    "\n",
    "print('log per level:', log_level_freq)\n",
    "print('\\nerror per service:', error_service_freq)\n",
    "\n",
    "most_occured_logs = sorted(top_logs, reverse=True)\n",
    "most_occured_errors = sorted(top_errors, reverse=True)\n",
    "\n",
    "print(\"\\nmost occured errors: \", most_occured_errors)\n",
    "print(\"\\nmost occured logs: \", most_occured_logs)\n",
    "\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9aa038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".logreportenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
